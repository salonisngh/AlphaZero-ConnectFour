{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fe9baf-f13a-4ad4-862c-9ef383c01cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "2.8.0+cu129\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import math\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "from tqdm.auto import trange\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2605ace0-91a5-4ec6-ab94-81cac50a0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectFour:\n",
    "    def __init__(self):\n",
    "        self.row_count = 6\n",
    "        self.column_count = 7\n",
    "        self.action_size = self.column_count\n",
    "        self.in_a_row = 4\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"ConnectFour\"\n",
    "        \n",
    "    def get_initial_state(self):\n",
    "        return np.zeros((self.row_count, self.column_count))\n",
    "    \n",
    "    def get_next_state(self, state, action, player):\n",
    "        row = np.max(np.where(state[:, action] == 0))\n",
    "        state[row, action] = player\n",
    "        return state\n",
    "    \n",
    "    def get_valid_moves(self, state):\n",
    "        return (state[0] == 0).astype(np.uint8)\n",
    "    \n",
    "    def check_win(self, state, action):\n",
    "        if action == None:\n",
    "            return False\n",
    "        \n",
    "        row = np.min(np.where(state[:, action] != 0))\n",
    "        column = action\n",
    "        player = state[row][column]\n",
    "\n",
    "        def count(offset_row, offset_column):\n",
    "            for i in range(1, self.in_a_row):\n",
    "                r = row + offset_row * i\n",
    "                c = action + offset_column * i\n",
    "                if (\n",
    "                    r < 0 \n",
    "                    or r >= self.row_count\n",
    "                    or c < 0 \n",
    "                    or c >= self.column_count\n",
    "                    or state[r][c] != player\n",
    "                ):\n",
    "                    return i - 1\n",
    "            return self.in_a_row - 1\n",
    "\n",
    "        return (\n",
    "            count(1, 0) >= self.in_a_row - 1 # vertical\n",
    "            or (count(0, 1) + count(0, -1)) >= self.in_a_row - 1 # horizontal\n",
    "            or (count(1, 1) + count(-1, -1)) >= self.in_a_row - 1 # top left diagonal\n",
    "            or (count(1, -1) + count(-1, 1)) >= self.in_a_row - 1 # top right diagonal\n",
    "        )\n",
    "    \n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if self.check_win(state, action):\n",
    "            return 1, True\n",
    "        if np.sum(self.get_valid_moves(state)) == 0:\n",
    "            return 0, True\n",
    "        return 0, False\n",
    "    \n",
    "    def get_opponent(self, player):\n",
    "        return -player\n",
    "    \n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "    \n",
    "    def change_perspective(self, state, player):\n",
    "        return state * player\n",
    "    \n",
    "    def get_encoded_state(self, state):\n",
    "        encoded_state = np.stack(\n",
    "            (state == -1, state == 0, state == 1)\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        if len(state.shape)==3: #batch,rows,columns incase of parallel so len =3 else it just just rows,columns len=2\n",
    "            encoded_state = np.swapaxes(encoded_state,0,1)            \n",
    "        \n",
    "        return encoded_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f607991-27be-4b89-a7e4-1151ab815a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,game,num_resBlocks,num_hidden,device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Conv2d(3,num_hidden,kernel_size =3,padding=1),\n",
    "            nn.BatchNorm2d(num_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
    "        )\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden,32,kernel_size =3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*game.row_count * game.column_count,game.action_size)\n",
    "        )\n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden,3,kernel_size =3,padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*game.row_count * game.column_count,1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.to(device)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy,value\n",
    "        \n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,num_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden,num_hidden,kernel_size = 3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden,num_hidden,kernel_size = 3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x+=residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c375c00-2b9c-4046-b3d2-826ed6ff46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game, args, state, parent=None, action_taken=None,prior=0, visit_count=0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        self.prior = prior\n",
    "        self.children = []\n",
    "        # self.expandable_moves = game.get_valid_moves(state)\n",
    "        \n",
    "        self.visit_count = visit_count\n",
    "        self.value_sum = 0\n",
    "        \n",
    "    def is_fully_expanded(self):\n",
    "        # return np.sum(self.expandable_moves) == 0 and len(self.children) > 0\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "        \n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb = ucb\n",
    "                \n",
    "        return best_child\n",
    "    \n",
    "    def get_ucb(self, child):\n",
    "        if child.visit_count==0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
    "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count+1))*child.prior\n",
    "    \n",
    "    def expand(self,policy):\n",
    "        for action,prob in enumerate(policy):\n",
    "            if prob>0:\n",
    "                child_state = self.state.copy()\n",
    "                child_state = self.game.get_next_state(child_state, action, 1)\n",
    "                child_state = self.game.change_perspective(child_state, player=-1)\n",
    "                child = Node(self.game, self.args, child_state, self, action,prob)\n",
    "                self.children.append(child)\n",
    "               \n",
    "    def backpropagate(self, value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "        \n",
    "        value = self.game.get_opponent_value(value)\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)  \n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, args,model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, state):\n",
    "        root = Node(self.game, self.args, state,visit_count=1)\n",
    "\n",
    "        policy, _ = self.model(\n",
    "            torch.tensor(self.game.get_encoded_state(state),device = self.model.device).unsqueeze(0)\n",
    "        )\n",
    "        policy = torch.softmax(policy,axis = 1).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        # add noise to our model\n",
    "        policy = (1-self.args['dirichlet_epsilon'])*policy + \\\n",
    "            self.args['dirichlet_epsilon']*np.random.dirichlet([self.args['dirichlet_alpha']]*self.game.action_size)\n",
    "\n",
    "        valid_moves = self.game.get_valid_moves(state)\n",
    "        policy *= valid_moves\n",
    "        policy /= np.sum(policy)\n",
    "        root.expand(policy)\n",
    "        \n",
    "        for search in range(self.args['num_searches']):\n",
    "            node = root\n",
    "            \n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "                \n",
    "            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "            value = self.game.get_opponent_value(value)\n",
    "            \n",
    "            if not is_terminal:\n",
    "                policy,value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(node.state),device = self.model.device).unsqueeze(0)\n",
    "                )\n",
    "                policy = torch.softmax(policy,axis =1).squeeze(0).cpu().numpy()\n",
    "                valid_moves = self.game.get_valid_moves(node.state)\n",
    "                policy*=valid_moves\n",
    "                policy/=np.sum(policy)\n",
    "\n",
    "                value = value.item()\n",
    "                node.expand(policy)\n",
    "                \n",
    "            node.backpropagate(value)    \n",
    "            \n",
    "            \n",
    "        action_probs = np.zeros(self.game.action_size)\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ab689fa-38dc-4b92-8dae-264b8a60c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "    def __init__(self,model,optimizer,game,args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.args = args\n",
    "        self.game = game\n",
    "        self.mcts = MCTS(game,args,model)\n",
    "\n",
    "    def selfPlay(self):\n",
    "        memory = []\n",
    "        player = 1\n",
    "        state = self.game.get_initial_state()\n",
    "\n",
    "        while True:\n",
    "            neutral_state = self.game.change_perspective(state,player)\n",
    "            action_probs = self.mcts.search(neutral_state)\n",
    "\n",
    "            memory.append((neutral_state,action_probs,player))\n",
    "            \n",
    "            temperature_action_probs = action_probs ** (1/self.args['temperature'])\n",
    "            temperature_action_probs /=np.sum(temperature_action_probs)\n",
    "            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
    "            state = self.game.get_next_state(state,action,player)\n",
    "            value,is_terminal = self.game.get_value_and_terminated(state,action)\n",
    "            if is_terminal:\n",
    "                returnMemory = []\n",
    "                for hist_neutral_state,hist_action_probs,hist_player in memory:\n",
    "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
    "                    returnMemory.append((self.game.get_encoded_state(hist_neutral_state),\n",
    "                                        hist_action_probs,\n",
    "                                        hist_outcome))\n",
    "                return returnMemory\n",
    "            player = self.game.get_opponent(player)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def train(self,memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0,len(memory),self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory)-1, batchIdx + self.args['batch_size'])]\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1,1)\n",
    "\n",
    "            state = torch.tensor(state,dtype = torch.float32, device = self.model.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype = torch.float32, device = self.model.device)\n",
    "            value_targets = torch.tensor(value_targets, dtype = torch.float32, device = self.model.device)\n",
    "\n",
    "            out_policy, out_value = self.model(state)\n",
    "            \n",
    "            policy_loss = F.cross_entropy(out_policy,policy_targets)\n",
    "            value_loss = F.mse_loss(out_value,value_targets)\n",
    "            loss = policy_loss+value_loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    \n",
    "    def learn(self):\n",
    "        for iteration in range(self.args['num_iterations']):\n",
    "            memory = []\n",
    "\n",
    "            self.model.eval()\n",
    "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
    "                memory+=self.selfPlay()\n",
    "            self.model.train()\n",
    "            for epoch in range(self.args['num_epochs']):\n",
    "                self.train(memory)\n",
    "            torch.save(self.model.state_dict(), f\"model_{iteration}_{self.game}.pt\")\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}_{self.game}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6527d7b5-c544-4d7e-acf3-e830e16304b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSParallel:\n",
    "    def __init__(self, game, args,model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, states, spGames):\n",
    "        \n",
    "        policy, _ = self.model(\n",
    "            torch.tensor(self.game.get_encoded_state(states),device = self.model.device)\n",
    "        )\n",
    "        policy = torch.softmax(policy,axis = 1).cpu().numpy()\n",
    "        \n",
    "        # add noise to our model\n",
    "        policy = (1-self.args['dirichlet_epsilon'])*policy + \\\n",
    "            self.args['dirichlet_epsilon']*np.random.dirichlet([self.args['dirichlet_alpha']]*self.game.action_size, size=policy.shape[0])\n",
    "\n",
    "        for i,spg in enumerate(spGames):\n",
    "            spg_policy = policy[i]\n",
    "            valid_moves = self.game.get_valid_moves(states[i])\n",
    "            spg_policy *= valid_moves\n",
    "            spg_policy /= np.sum(spg_policy)\n",
    "    \n",
    "            spg.root = Node(self.game, self.args, states[i],visit_count=1)\n",
    "            spg.root.expand(spg_policy)\n",
    "        \n",
    "        for search in range(self.args['num_searches']):\n",
    "            for spg in spGames:\n",
    "                spg.node = None\n",
    "                node = spg.root\n",
    "                \n",
    "                while node.is_fully_expanded():\n",
    "                    node = node.select()\n",
    "                    \n",
    "                value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "                value = self.game.get_opponent_value(value)\n",
    "                \n",
    "                if is_terminal:\n",
    "                        node.backpropagate(value)   \n",
    "                else:\n",
    "                    spg.node = node\n",
    "            \n",
    "            expandable_spGames = [mappingIdx for mappingIdx in range(len(spGames)) if spGames[mappingIdx].node is not None]\n",
    "            \n",
    "            if len(expandable_spGames)>0:\n",
    "                states = np.stack([spGames[mappingIdx].node.state for mappingIdx in expandable_spGames])\n",
    "                \n",
    "                policy,value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(states),device = self.model.device)\n",
    "                )\n",
    "                policy = torch.softmax(policy,axis =1).cpu().numpy()\n",
    "                value = value.cpu().numpy()\n",
    "\n",
    "            for i,mappingIdx in enumerate(expandable_spGames):\n",
    "                node = spGames[mappingIdx].node\n",
    "                spg_policy,spg_value = policy[i],value[i]\n",
    "                \n",
    "                valid_moves = self.game.get_valid_moves(node.state)\n",
    "                spg_policy*=valid_moves\n",
    "                spg_policy/=np.sum(spg_policy)\n",
    "\n",
    "                node.expand(spg_policy)\n",
    "                node.backpropagate(spg_value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96c40688-c15a-4bbd-96fe-4822acbbe0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZeroParallel:\n",
    "    def __init__(self,model,optimizer,game,args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.args = args\n",
    "        self.game = game\n",
    "        self.mcts = MCTSParallel(game,args,model)\n",
    "\n",
    "    def selfPlay(self):\n",
    "        return_memory = []\n",
    "        player = 1\n",
    "        spGames = [SPG(self.game) for _ in range(self.args['num_parallel_games'])]\n",
    "\n",
    "        while len(spGames)>0:\n",
    "            states = np.stack([spg.state for spg in spGames])\n",
    "            \n",
    "            neutral_states = self.game.change_perspective(states,player)\n",
    "            self.mcts.search(neutral_states, spGames)\n",
    "\n",
    "            for i in range(len(spGames))[::-1]:\n",
    "                spg = spGames[i]\n",
    "                action_probs = np.zeros(self.game.action_size)\n",
    "                for child in spg.root.children:\n",
    "                    action_probs[child.action_taken] = child.visit_count\n",
    "                action_probs /= np.sum(action_probs)\n",
    "    \n",
    "                spg.memory.append((spg.root.state,action_probs,player))\n",
    "                \n",
    "                temperature_action_probs = action_probs ** (1/self.args['temperature'])\n",
    "                temperature_action_probs /= np.sum(temperature_action_probs)\n",
    "                action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
    "                \n",
    "                spg.state = self.game.get_next_state(spg.state,action,player)\n",
    "                value,is_terminal = self.game.get_value_and_terminated(spg.state,action)\n",
    "                \n",
    "                if is_terminal:\n",
    "                    for hist_neutral_state,hist_action_probs,hist_player in spg.memory:\n",
    "                        hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
    "                        return_memory.append((self.game.get_encoded_state(hist_neutral_state),\n",
    "                                            hist_action_probs,\n",
    "                                            hist_outcome))\n",
    "                    del spGames[i]\n",
    "            player = self.game.get_opponent(player)\n",
    "                \n",
    "        return return_memory\n",
    "            \n",
    "        \n",
    "    def train(self,memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0,len(memory),self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory)-1, batchIdx + self.args['batch_size'])]\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1,1)\n",
    "\n",
    "            state = torch.tensor(state,dtype = torch.float32, device = self.model.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype = torch.float32, device = self.model.device)\n",
    "            value_targets = torch.tensor(value_targets, dtype = torch.float32, device = self.model.device)\n",
    "\n",
    "            out_policy, out_value = self.model(state)\n",
    "            \n",
    "            policy_loss = F.cross_entropy(out_policy,policy_targets)\n",
    "            value_loss = F.mse_loss(out_value,value_targets)\n",
    "            loss = policy_loss+value_loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    \n",
    "    def learn(self):\n",
    "        for iteration in range(self.args['num_iterations']):\n",
    "            memory = []\n",
    "\n",
    "            self.model.eval()\n",
    "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations'] // self.args['num_parallel_games']):\n",
    "                memory+=self.selfPlay()\n",
    "            self.model.train()\n",
    "            for epoch in range(self.args['num_epochs']):\n",
    "                self.train(memory)\n",
    "            torch.save(self.model.state_dict(), f\"model_{iteration}_{self.game}.pt\")\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}_{self.game}.pt\")\n",
    "\n",
    "class SPG:\n",
    "    def __init__(self,game):\n",
    "        self.state = game.get_initial_state()\n",
    "        self.memory = []\n",
    "        self.root = None\n",
    "        self.node = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac5cdc05-415b-43a5-8ea6-db8a2b9b98f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbd129580a141b59c487d547c23bf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce8208c76294ce6b1d683624c1a119a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58140fdadae044e3878f37139d81e861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13bd09951b741ba9b7614f7a453007b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9ddfec076347348528ee4daa0c3007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56083c957af544f486cf5725591a1a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game = ConnectFour()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNet(game,9,128,device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001, weight_decay = 0.0001)\n",
    "args = {\n",
    "    'C':2,\n",
    "    'num_searches':600,\n",
    "    'num_iterations':6,\n",
    "    'num_selfPlay_iterations':500,\n",
    "    'num_parallel_games':250,\n",
    "    'num_epochs':4,\n",
    "    'batch_size':128,\n",
    "    'temperature':1.25,\n",
    "    'dirichlet_epsilon':0.25,\n",
    "    'dirichlet_alpha':0.3\n",
    "}\n",
    "\n",
    "alphaZero = AlphaZeroParallel(model,optimizer,game,args)\n",
    "alphaZero.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f98c10d-12be-4239-99cd-ed83dfc1a244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "valid_moves [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.  0.]]\n",
      "valid_moves [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.  0.]]\n",
      "valid_moves [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0. -1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1. -1.  0.  0.]]\n",
      "valid_moves [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1. -1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1. -1. -1.  0.]]\n",
      "valid_moves [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "1: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1. -1. -1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1. -1. -1. -1.]]\n",
      "-1 won\n"
     ]
    }
   ],
   "source": [
    "game = ConnectFour()\n",
    "player = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 100,\n",
    "    'dirichlet_epsilon':0.0,\n",
    "    'dirichlet_alpha':0.3\n",
    "}\n",
    "\n",
    "model = ResNet(game,9,128,device)\n",
    "model.load_state_dict(torch.load(\"model_5_ConnectFour.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "mcts = MCTS(game, args,model)\n",
    "\n",
    "state = game.get_initial_state()\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    \n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        print(\"valid_moves\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}:\"))\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not valid\")\n",
    "            continue\n",
    "            \n",
    "    else:\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        mcts_probs = mcts.search(neutral_state)\n",
    "        action = np.argmax(mcts_probs)\n",
    "        \n",
    "    state = game.get_next_state(state, action, player)\n",
    "    \n",
    "    value, is_terminal = game.get_value_and_terminated(state, action)\n",
    "    \n",
    "    if is_terminal:\n",
    "        print(state)\n",
    "        if value == 1:\n",
    "            print(player, \"won\")\n",
    "        else:\n",
    "            print(\"draw\")\n",
    "        break\n",
    "        \n",
    "    player = game.get_opponent(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6e5daf6-4a70-45d2-b733-48eb3be62201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import sys \n",
    "import time\n",
    "from pygame import gfxdraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "227bddd9-9e7d-4a3d-bc80-effd4895a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Layout / scaling ----------\n",
    "MARGIN = 16  # pixels margin on all sides\n",
    "MAX_SQUARE = 140  # max pixel size per square to avoid huge tiles on large monitors\n",
    "MIN_SQUARE = 60   # minimum size to keep things playable\n",
    "\n",
    "# These will be computed in `init_layout()` based on the user's display and game size\n",
    "SQUARESIZE = None\n",
    "RADIUS = None\n",
    "OFFSET_X = None\n",
    "OFFSET_Y = None\n",
    "WIDTH = None\n",
    "HEIGHT = None\n",
    "SIZE = None\n",
    "FPS = 60\n",
    "\n",
    "BLACK = (0,0,0)\n",
    "WHITE = (255,255,255)\n",
    "BLUE = (13, 71, 161)\n",
    "RED = (220, 20, 60)     # player == 1 (human)\n",
    "YELLOW = (240, 200, 0)  # player == -1 (model)\n",
    "GREEN = (50,205,50)\n",
    "\n",
    "\n",
    "def init_layout(game, scale=0.85):\n",
    "    global SQUARESIZE, RADIUS, OFFSET_X, OFFSET_Y, WIDTH, HEIGHT, SIZE\n",
    "\n",
    "    pygame.init()\n",
    "    info = pygame.display.Info()\n",
    "    screen_w, screen_h = info.current_w, info.current_h\n",
    "\n",
    "    cols = game.column_count\n",
    "    rows = game.row_count\n",
    "    # reserve space for the top preview row as well: (rows + 1)\n",
    "    available_w = max(300, screen_w - 2*MARGIN)\n",
    "    available_h = max(400, screen_h - 2*MARGIN)\n",
    "\n",
    "    # compute square limited by width and height\n",
    "    sq_w = (available_w - 2*MARGIN) // cols\n",
    "    sq_h = (available_h - 2*MARGIN) // (rows + 1)\n",
    "\n",
    "    # apply scale to make everything a bit smaller\n",
    "    computed = int(min(sq_w, sq_h) * scale)\n",
    "\n",
    "    SQUARESIZE = int(max(MIN_SQUARE, min(MAX_SQUARE, computed)))\n",
    "    RADIUS = int(SQUARESIZE/2 - 6)\n",
    "\n",
    "    # compute final window size with margins\n",
    "    WIDTH = cols * SQUARESIZE + 2*MARGIN\n",
    "    HEIGHT = (rows + 1) * SQUARESIZE + 2*MARGIN\n",
    "    OFFSET_X = MARGIN\n",
    "    OFFSET_Y = MARGIN\n",
    "    SIZE = (WIDTH, HEIGHT)\n",
    "\n",
    "    return SIZE\n",
    "\n",
    "# ---------- Drawing helpers (single final update per frame) ----------\n",
    "\n",
    "def draw_board(surface, state, game, highlight_positions=None, preview_col=None):\n",
    "    \"\"\"\n",
    "    Draws the board to `surface`. `state` uses values: 0 empty, 1 human, -1 model.\n",
    "    preview_col: optional column index to show the preview disc at the top (no update here).\n",
    "    \"\"\"\n",
    "    surface.fill(BLACK)\n",
    "\n",
    "    cols = game.column_count\n",
    "    rows = game.row_count\n",
    "\n",
    "    # draw grid and discs\n",
    "    for c in range(cols):\n",
    "        for r in range(rows):\n",
    "            x = OFFSET_X + c*SQUARESIZE\n",
    "            y = OFFSET_Y + (r+1)*SQUARESIZE\n",
    "            pygame.draw.rect(surface, BLUE, (x, y, SQUARESIZE, SQUARESIZE))\n",
    "            val = int(state[r, c])\n",
    "            center = (int(x + SQUARESIZE/2), int(y + SQUARESIZE/2))\n",
    "            if val == 0:\n",
    "                pygame.draw.circle(surface, BLACK, center, RADIUS)\n",
    "            elif val == 1:\n",
    "                pygame.draw.circle(surface, RED, center, RADIUS)\n",
    "            elif val == -1:\n",
    "                pygame.draw.circle(surface, YELLOW, center, RADIUS)\n",
    "\n",
    "    # draw preview disc at top (if any) using the preview_col\n",
    "    if preview_col is not None and 0 <= preview_col < cols:\n",
    "        px = OFFSET_X + preview_col*SQUARESIZE + SQUARESIZE//2\n",
    "        py = OFFSET_Y + SQUARESIZE//2\n",
    "        pygame.draw.circle(surface, RED, (px, py), RADIUS)\n",
    "\n",
    "    # highlight winning positions\n",
    "    if highlight_positions:\n",
    "        for (r,c) in highlight_positions:\n",
    "            cx = OFFSET_X + c*SQUARESIZE + SQUARESIZE//2\n",
    "            cy = OFFSET_Y + (r+1)*SQUARESIZE + SQUARESIZE//2\n",
    "            pygame.draw.circle(surface, GREEN, (cx, cy), RADIUS, 6)\n",
    "\n",
    "\n",
    "def animate_drop(surface, state, game, col, player_value, fps=FPS):\n",
    "    \"\"\"\n",
    "    Animate a disc falling into column `col` (visually). This routine updates\n",
    "    the display while animating and returns once the disc has visually landed.\n",
    "    It does NOT modify the logical `state` (the caller should call get_next_state).\n",
    "    \"\"\"\n",
    "    cols = game.column_count\n",
    "    rows = game.row_count\n",
    "\n",
    "    # find the bottom-most empty row\n",
    "    open_row = None\n",
    "    for r in range(rows-1, -1, -1):\n",
    "        if state[r, col] == 0:\n",
    "            open_row = r\n",
    "            break\n",
    "    if open_row is None:\n",
    "        return\n",
    "\n",
    "    x = OFFSET_X + col*SQUARESIZE + SQUARESIZE//2\n",
    "    target_y = OFFSET_Y + (open_row+1)*SQUARESIZE + SQUARESIZE//2\n",
    "    y = OFFSET_Y + SQUARESIZE//2\n",
    "\n",
    "    clock = pygame.time.Clock()\n",
    "    vel = 0.0\n",
    "    acc = 2.8\n",
    "    color = RED if player_value == 1 else YELLOW\n",
    "\n",
    "    while y < target_y:\n",
    "        clock.tick(fps)\n",
    "        vel += acc\n",
    "        y += vel\n",
    "        # draw board and falling disc\n",
    "        draw_board(surface, state, game)\n",
    "        pygame.draw.circle(surface, color, (x, min(int(y), target_y)), RADIUS)\n",
    "        pygame.display.update()\n",
    "\n",
    "    # final frame\n",
    "    draw_board(surface, state, game)\n",
    "    pygame.draw.circle(surface, color, (x, target_y), RADIUS)\n",
    "    pygame.display.update()\n",
    "\n",
    "\n",
    "# ---------- Model/MCTS integration helper ----------\n",
    "def get_model_action_from_mcts(game, mcts, state, player):\n",
    "    valid = game.get_valid_moves(state)\n",
    "    valid_indices = [i for i in range(game.action_size) if valid[i] == 1]\n",
    "    if len(valid_indices) == 0:\n",
    "        return None\n",
    "    if mcts is None:\n",
    "        return int(random.choice(valid_indices))\n",
    "    try:\n",
    "        neutral_state = game.change_perspective(state.copy(), player)\n",
    "        mcts_probs = mcts.search(neutral_state)\n",
    "        action = int(np.argmax(mcts_probs))\n",
    "        if valid[action] == 1:\n",
    "            return action\n",
    "        for idx in np.argsort(-np.array(mcts_probs)):\n",
    "            if valid[int(idx)] == 1:\n",
    "                return int(idx)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: mcts/model inference failed:\", e)\n",
    "    return int(random.choice(valid_indices))\n",
    "\n",
    "\n",
    "# ---------- Main GUI loop ----------\n",
    "def run_gui(game, state, mcts=None, human_value=1, model_value=-1, model_move_delay_ms=600):\n",
    "    # initialize layout based on display\n",
    "    size = init_layout(game)\n",
    "    screen = pygame.display.set_mode(size)\n",
    "    pygame.display.set_caption(\"Connect Four - GUI\")\n",
    "    font = pygame.font.SysFont(\"Arial\", max(18, SQUARESIZE//5))\n",
    "    small_font = pygame.font.SysFont(\"Arial\", max(14, SQUARESIZE//6))\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    assert state.shape == (game.row_count, game.column_count), \"State shape mismatch with game dimensions.\"\n",
    "\n",
    "    player = human_value\n",
    "    play_vs_model = True if mcts is not None else False\n",
    "    game_over = False\n",
    "    highlight = None\n",
    "    info_text = \"Your turn (Red). Click a column to drop.\"\n",
    "    last_model_move_time = 0\n",
    "    preview_col = None  # column index under mouse for preview\n",
    "\n",
    "    # initial draw\n",
    "    draw_board(screen, state, game, highlight_positions=highlight, preview_col=None)\n",
    "    pygame.display.update()\n",
    "\n",
    "    running = True\n",
    "    while running:\n",
    "        clock.tick(FPS)\n",
    "        # event handling\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "                break\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_q:\n",
    "                    running = False\n",
    "                    break\n",
    "                if event.key == pygame.K_r:\n",
    "                    state[:] = game.get_initial_state()\n",
    "                    player = human_value\n",
    "                    game_over = False\n",
    "                    highlight = None\n",
    "                    info_text = \"Your turn (Red). Click a column to drop.\"\n",
    "                if event.key == pygame.K_m:\n",
    "                    play_vs_model = not play_vs_model\n",
    "                    state[:] = game.get_initial_state()\n",
    "                    player = human_value\n",
    "                    game_over = False\n",
    "                    highlight = None\n",
    "                    info_text = \"Mode toggled. \" + (\"Human vs Model.\" if play_vs_model else \"Human vs Human.\")\n",
    "\n",
    "            if event.type == pygame.MOUSEMOTION:\n",
    "                mx, my = event.pos\n",
    "                # compute column under mouse taking margins into account\n",
    "                col = (mx - OFFSET_X) // SQUARESIZE\n",
    "                if 0 <= col < game.column_count:\n",
    "                    preview_col = int(col)\n",
    "                else:\n",
    "                    preview_col = None\n",
    "\n",
    "            if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                if game_over:\n",
    "                    state[:] = game.get_initial_state()\n",
    "                    player = human_value\n",
    "                    game_over = False\n",
    "                    preview_col = None\n",
    "                    highlight = None\n",
    "                    info_text = \"Your turn (Red). Click a column to drop.\"\n",
    "                    continue\n",
    "\n",
    "                mx, my = event.pos\n",
    "                col = (mx - OFFSET_X) // SQUARESIZE\n",
    "                if col < 0 or col >= game.column_count:\n",
    "                    continue\n",
    "\n",
    "                if player == human_value:\n",
    "                    valid_moves = game.get_valid_moves(state)\n",
    "                    if valid_moves[col] == 0:\n",
    "                        info_text = \"Invalid move. Choose another column.\"\n",
    "                    else:\n",
    "                        animate_drop(screen, state, game, col, player)\n",
    "                        state = game.get_next_state(state, int(col), player)\n",
    "                        val, terminated = game.get_value_and_terminated(state, int(col))\n",
    "                        if terminated:\n",
    "                            game_over = True\n",
    "                            if val == 1:\n",
    "                                info_text = f\"{player} (You) won! Press R to restart.\"\n",
    "                            else:\n",
    "                                info_text = \"Draw! Press R to restart.\"\n",
    "                            highlight = None\n",
    "                        else:\n",
    "                            if play_vs_model:\n",
    "                                player = model_value\n",
    "                                info_text = \"Model thinking...\"\n",
    "                                last_model_move_time = pygame.time.get_ticks()\n",
    "                            else:\n",
    "                                player = model_value\n",
    "                                info_text = \"Player 2's turn.\"\n",
    "\n",
    "                else:\n",
    "                    valid_moves = game.get_valid_moves(state)\n",
    "                    if valid_moves[col] == 0:\n",
    "                        info_text = \"Invalid move. Choose another column.\"\n",
    "                    else:\n",
    "                        animate_drop(screen, state, game, col, player)\n",
    "                        state = game.get_next_state(state, int(col), player)\n",
    "                        val, terminated = game.get_value_and_terminated(state, int(col))\n",
    "                        if terminated:\n",
    "                            game_over = True\n",
    "                            if val == 1:\n",
    "                                info_text = f\"{player} (Player 2) won! Press R to restart.\"\n",
    "                            else:\n",
    "                                info_text = \"Draw! Press R to restart.\"\n",
    "                            highlight = None\n",
    "                        else:\n",
    "                            player = human_value\n",
    "                            info_text = \"Your turn (Red).\"\n",
    "\n",
    "        # model turn (non-blocking)\n",
    "        if not game_over and play_vs_model and player == model_value:\n",
    "            now = pygame.time.get_ticks()\n",
    "            if now - last_model_move_time >= model_move_delay_ms:\n",
    "                action = get_model_action_from_mcts(game, mcts, state.copy(), player)\n",
    "                if action is None:\n",
    "                    game_over = True\n",
    "                    info_text = \"No valid moves: draw.\"\n",
    "                else:\n",
    "                    animate_drop(screen, state, game, action, player)\n",
    "                    state = game.get_next_state(state, int(action), player)\n",
    "                    val, terminated = game.get_value_and_terminated(state, int(action))\n",
    "                    if terminated:\n",
    "                        game_over = True\n",
    "                        if val == 1:\n",
    "                            info_text = f\"{player} (Model) won! Press R to restart.\"\n",
    "                        else:\n",
    "                            info_text = \"Draw! Press R to restart.\"\n",
    "                        highlight = None\n",
    "                    else:\n",
    "                        player = human_value\n",
    "                        info_text = \"Your turn (Red).\"\n",
    "\n",
    "        # final draw (single update per frame)\n",
    "        draw_board(screen, state, game, highlight_positions=highlight, preview_col=preview_col if (not game_over and player==human_value) else None)\n",
    "        info_surf = font.render(info_text, True, WHITE)\n",
    "        screen.blit(info_surf, (OFFSET_X + 6, OFFSET_Y + 6))\n",
    "        mode_text = f\"Mode: {'Human vs Model' if play_vs_model else 'Human vs Human'}  |  Press M to toggle, R to restart, Q to quit\"\n",
    "        mode_surf = small_font.render(mode_text, True, WHITE)\n",
    "        screen.blit(mode_surf, (OFFSET_X + 6, HEIGHT - OFFSET_Y - small_font.get_height() - 6))\n",
    "        pygame.display.update()\n",
    "\n",
    "    pygame.quit()\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fad6ba61-4f40-4fe4-a039-6e77d36bf5f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "game = ConnectFour()\n",
    "state = game.get_initial_state()\n",
    "player = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 100,\n",
    "    'dirichlet_epsilon':0.0,\n",
    "    'dirichlet_alpha':0.3\n",
    "}\n",
    "\n",
    "model = ResNet(game,9,128,device)\n",
    "model.load_state_dict(torch.load(\"model_5_ConnectFour.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "mcts = MCTS(game, args,model)\n",
    "\n",
    "state = game.get_initial_state()\n",
    "\n",
    "run_gui(game,state,mcts= mcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "040f1740-b78a-4e2a-871b-f8ca3d22d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeuristicAgent:\n",
    "    def __init__(self, game):\n",
    "        self.game = game\n",
    "\n",
    "    def select_action(self, state, player):\n",
    "        valid_moves = self.game.get_valid_moves(state)\n",
    "        valid_actions = np.where(valid_moves == 1)[0]\n",
    "\n",
    "        # 1. Try to play a winning move for current player\n",
    "        for a in valid_actions:\n",
    "            tmp = state.copy()\n",
    "            tmp = self.game.get_next_state(tmp, a, player)\n",
    "            value, is_terminal = self.game.get_value_and_terminated(tmp, a)\n",
    "            # value = 1 means the player who just moved (player) wins\n",
    "            if is_terminal and value == 1:\n",
    "                return int(a)\n",
    "\n",
    "        # 2. Try to block opponent's immediate win\n",
    "        opp = self.game.get_opponent(player)\n",
    "        for a in valid_actions:\n",
    "            tmp = state.copy()\n",
    "            tmp = self.game.get_next_state(tmp, a, opp)\n",
    "            value, is_terminal = self.game.get_value_and_terminated(tmp, a)\n",
    "            if is_terminal and value == 1:\n",
    "                return int(a)\n",
    "\n",
    "        # 3. Otherwise prefer center columns\n",
    "        # center preference: [3,2,4,1,5,0,6] for a 7-column board\n",
    "        center_order = sorted(valid_actions, key=lambda c: abs(c - (self.game.column_count // 2)))\n",
    "        return int(center_order[0])\n",
    "\n",
    "class MCTSAgent:\n",
    "    def __init__(self, game, model, args_eval):\n",
    "        self.game = game\n",
    "        self.model = model\n",
    "        self.args = args_eval.copy()\n",
    "        # disable root noise for evaluation\n",
    "        self.args['dirichlet_epsilon'] = 0.0\n",
    "        self.mcts = MCTS(game, self.args, model)\n",
    "\n",
    "    def select_action(self, state, player):\n",
    "        neutral_state = self.game.change_perspective(state, player)\n",
    "        action_probs = self.mcts.search(neutral_state)\n",
    "        return int(np.argmax(action_probs))  # greedy for evaluation\n",
    "\n",
    "\n",
    "def play_game_with_length(game, agent1, agent2):\n",
    "    \"\"\"\n",
    "    Returns (result, moves)\n",
    "    result: +1 if agent1 wins, -1 if agent2 wins, 0 if draw\n",
    "    moves: number of moves played\n",
    "    \"\"\"\n",
    "    state = game.get_initial_state()\n",
    "    current_player = 1\n",
    "    moves = 0\n",
    "\n",
    "    while True:\n",
    "        if current_player == 1:\n",
    "            action = agent1.select_action(state, current_player)\n",
    "        else:\n",
    "            action = agent2.select_action(state, current_player)\n",
    "\n",
    "        state = game.get_next_state(state, action, current_player)\n",
    "        moves += 1\n",
    "        value, is_terminal = game.get_value_and_terminated(state, action)\n",
    "        if is_terminal:\n",
    "            if value == 1:\n",
    "                return (1 if current_player == 1 else -1), moves\n",
    "            else:\n",
    "                return 0, moves\n",
    "        current_player = game.get_opponent(current_player)\n",
    "\n",
    "\n",
    "def evaluate_vs_heuristic_for_checkpoint(game, args, ckpt_path,\n",
    "                                         num_games=40, mcts_search_override=200, device=None):\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "\n",
    "    # load model\n",
    "    model = ResNet(game, num_resBlocks=9, num_hidden=128, device=device)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    args_eval = args.copy()\n",
    "    args_eval['dirichlet_epsilon'] = 0.0\n",
    "    if mcts_search_override is not None:\n",
    "        args_eval['num_searches'] = mcts_search_override\n",
    "\n",
    "    mcts_agent = MCTSAgent(game, model, args_eval)\n",
    "    heuristic_agent = HeuristicAgent(game)\n",
    "\n",
    "    wins = losses = draws = 0\n",
    "    moves_list = []\n",
    "\n",
    "    wins_as_first = wins_as_second = 0\n",
    "    games_as_first = games_as_second = 0\n",
    "\n",
    "    for i in range(num_games):\n",
    "        if i % 2 == 0:\n",
    "            # model as player 1 (agent1)\n",
    "            result, moves = play_game_with_length(game, mcts_agent, heuristic_agent)\n",
    "            games_as_first += 1\n",
    "            if result == 1:\n",
    "                wins_as_first += 1\n",
    "        else:\n",
    "            # heuristic as player 1, model as player -1 (agent2)\n",
    "            result, moves = play_game_with_length(game, heuristic_agent, mcts_agent)\n",
    "            result = -result  # flip perspective to keep +1 = model win\n",
    "            games_as_second += 1\n",
    "            if result == 1:\n",
    "                wins_as_second += 1\n",
    "\n",
    "        moves_list.append(moves)\n",
    "\n",
    "        if result == 1:\n",
    "            wins += 1\n",
    "        elif result == -1:\n",
    "            losses += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "    total = wins + losses + draws\n",
    "    win_rate = wins / total if total > 0 else 0.0\n",
    "    avg_moves = float(np.mean(moves_list)) if moves_list else 0.0\n",
    "\n",
    "    win_rate_first = wins_as_first / games_as_first if games_as_first > 0 else 0.0\n",
    "    win_rate_second = wins_as_second / games_as_second if games_as_second > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"checkpoint\": ckpt_path,\n",
    "        \"games\": total,\n",
    "        \"wins\": wins,\n",
    "        \"losses\": losses,\n",
    "        \"draws\": draws,\n",
    "        \"win_rate\": win_rate,\n",
    "        \"avg_moves\": avg_moves,\n",
    "        \"win_rate_first\": win_rate_first,\n",
    "        \"win_rate_second\": win_rate_second,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ab1029f-6def-4b30-a2f7-31fd0d2a13e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'checkpoint': 'model_0_ConnectFour.pt', 'games': 30, 'wins': 15, 'losses': 15, 'draws': 0, 'win_rate': 0.5, 'avg_moves': 18.0, 'win_rate_first': 1.0, 'win_rate_second': 0.0}\n",
      "{'checkpoint': 'model_1_ConnectFour.pt', 'games': 30, 'wins': 15, 'losses': 0, 'draws': 15, 'win_rate': 0.5, 'avg_moves': 24.5, 'win_rate_first': 1.0, 'win_rate_second': 0.0}\n",
      "{'checkpoint': 'model_2_ConnectFour.pt', 'games': 30, 'wins': 30, 'losses': 0, 'draws': 0, 'win_rate': 1.0, 'avg_moves': 14.5, 'win_rate_first': 1.0, 'win_rate_second': 1.0}\n",
      "{'checkpoint': 'model_3_ConnectFour.pt', 'games': 30, 'wins': 30, 'losses': 0, 'draws': 0, 'win_rate': 1.0, 'avg_moves': 18.5, 'win_rate_first': 1.0, 'win_rate_second': 1.0}\n",
      "{'checkpoint': 'model_4_ConnectFour.pt', 'games': 30, 'wins': 30, 'losses': 0, 'draws': 0, 'win_rate': 1.0, 'avg_moves': 20.5, 'win_rate_first': 1.0, 'win_rate_second': 1.0}\n",
      "{'checkpoint': 'model_5_ConnectFour.pt', 'games': 30, 'wins': 15, 'losses': 0, 'draws': 15, 'win_rate': 0.5, 'avg_moves': 31.5, 'win_rate_first': 1.0, 'win_rate_second': 0.0}\n"
     ]
    }
   ],
   "source": [
    "game = ConnectFour()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "results = []\n",
    "for i in range(0, 6):\n",
    "    ckpt = f\"model_{i}_{game}.pt\"  # or \"model_{}_ConnectFour.pt\"\n",
    "    res = evaluate_vs_heuristic_for_checkpoint(\n",
    "        game, args, ckpt, num_games=30, mcts_search_override=200, device=device\n",
    "    )\n",
    "    print(res)\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ef80c6b-2ccc-4d2a-a3d5-83a2c5cd3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_first_move_stats(game, model, args_eval, num_games=50, device=None):\n",
    "    \"\"\"\n",
    "    Returns vector of shape (7,)  frequency of each column as model's first move.\n",
    "    \"\"\"\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    model.eval()\n",
    "    agent = MCTSAgent(game, model, args_eval)\n",
    "\n",
    "    counts = np.zeros(game.action_size, dtype=int)\n",
    "\n",
    "    for _ in range(num_games):\n",
    "        state = game.get_initial_state()\n",
    "        player = 1\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        action_probs = agent.mcts.search(neutral_state)\n",
    "        first_action = int(np.argmax(action_probs))\n",
    "        counts[first_action] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "game = ConnectFour()\n",
    "\n",
    "args_eval = args.copy()\n",
    "args_eval[\"dirichlet_epsilon\"] = 0.0        # no exploration noise\n",
    "args_eval[\"num_searches\"] = 200             # smaller search for speed\n",
    "\n",
    "models = [f\"model_{i}_ConnectFour.pt\" for i in range(6)]\n",
    "heatmap_data = []\n",
    "\n",
    "for ckpt in models:\n",
    "    model = ResNet(game, 9, 128, device)\n",
    "    model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "    counts = collect_first_move_stats(game, model, args_eval, num_games=40, device=device)\n",
    "    heatmap_data.append(counts)\n",
    "\n",
    "heatmap_data = np.array(heatmap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7dbbc9f9-1620-46fb-978c-ec9eed304507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap_probs = heatmap_data / heatmap_data.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(\n",
    "    heatmap_probs,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"YlOrRd\",\n",
    "    xticklabels=range(heatmap_probs.shape[1]),\n",
    "    yticklabels=[f\"model_{i}\" for i in range(len(models))]\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Column\")\n",
    "plt.ylabel(\"Model Iteration\")\n",
    "plt.title(\"Opening Move Heatmap  First Move Choice Probability\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
